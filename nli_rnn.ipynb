{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nli_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBfIhmPGKW5A"
      },
      "source": [
        "import torch\r\n",
        "import tqdm\r\n",
        "import torch.nn as nn\r\n",
        "from torchtext import data, datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EEubSQt5fJzm",
        "outputId": "469441c4-d22d-4744-845e-33444e2a6e68"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Jg-YIULaqI"
      },
      "source": [
        "TEXT = data.Field(tokenize=\"spacy\", lower=True)\r\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icMm52WeLamq"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SNLI.splits(TEXT, LABEL)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ7F6tHXLugC",
        "outputId": "827b0b5c-06c7-4041-ef31-9517f1072900"
      },
      "source": [
        "vars(train_data[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hypothesis': ['a',\n",
              "  'person',\n",
              "  'is',\n",
              "  'training',\n",
              "  'his',\n",
              "  'horse',\n",
              "  'for',\n",
              "  'a',\n",
              "  'competition',\n",
              "  '.'],\n",
              " 'label': 'neutral',\n",
              " 'premise': ['a',\n",
              "  'person',\n",
              "  'on',\n",
              "  'a',\n",
              "  'horse',\n",
              "  'jumps',\n",
              "  'over',\n",
              "  'a',\n",
              "  'broken',\n",
              "  'down',\n",
              "  'airplane',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb2MCXLWXNiC",
        "outputId": "793e5c6e-5402-4ec7-b2fd-ced9282598d8"
      },
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(549367, 9842, 9824)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPxK8MlJLuce"
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=2)\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qocMcM0LuZ-",
        "outputId": "a89482ad-1f39-4c09-88d5-616146d07219"
      },
      "source": [
        "len(TEXT.vocab), LABEL.vocab.stoi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23566,\n",
              " defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'contradiction': 1, 'entailment': 0, 'neutral': 2}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVxw2T9dLakH"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, pad_idx):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size, padding_idx=pad_idx)\r\n",
        "        self.fc_in = nn.Linear(embedding_size, hidden_size)\r\n",
        "        self.lstm_layers = nn.LSTM(hidden_size, hidden_size, num_layers=2, bidirectional=True, dropout=0.25)\r\n",
        "\r\n",
        "        self.fc_layers = nn.ModuleList([nn.Linear(hidden_size * 4, hidden_size * 4) for _ in range(3)])\r\n",
        "        self.fc_out = nn.Linear(hidden_size * 4, output_size)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(0.25)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, p, h):\r\n",
        "        p_seq_len, batch_size = p.shape\r\n",
        "        h_seq_len = h.shape[0]\r\n",
        "\r\n",
        "        p_embedded = self.embedding(p)\r\n",
        "        h_embedded = self.embedding(h)\r\n",
        "\r\n",
        "        p_activ = self.relu(self.fc_in(p_embedded))\r\n",
        "        h_activ = self.relu(self.fc_in(h_embedded))\r\n",
        "\r\n",
        "        po, (ph, pc) = self.lstm_layers(p_activ)\r\n",
        "        ho, (hh, hc) = self.lstm_layers(h_activ)\r\n",
        "\r\n",
        "        p_hidden = torch.cat((ph[-1, :, :], ph[-2, :, :]), dim=1)\r\n",
        "        h_hidden = torch.cat((hh[-1, :, :], hh[-2, :, :]), dim=1)\r\n",
        "        hidden = torch.cat((p_hidden, h_hidden), dim=1)\r\n",
        "\r\n",
        "        for fc in self.fc_layers:\r\n",
        "            hidden = self.relu(fc(hidden))\r\n",
        "            hidden = self.dropout(hidden)\r\n",
        "\r\n",
        "        output = self.fc_out(hidden)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IOfY3zsMDbF"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "epochs = 10\r\n",
        "batch_size = 512\r\n",
        "input_size = len(TEXT.vocab)\r\n",
        "embedding_size = 300\r\n",
        "hidden_size = 300\r\n",
        "output_size = len(LABEL.vocab)\r\n",
        "pad_idx = TEXT.vocab.stoi[\"<pad>\"] "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNSYpFuTMDXu",
        "outputId": "f7a43e34-c624-4ac6-cebe-06aaf6f1ac54"
      },
      "source": [
        "device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKDIwCIvXu78"
      },
      "source": [
        "train_batches, test_batches = data.BucketIterator.splits((train_data, test_data), batch_size=batch_size, device=device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOL3MAg8X_Jo",
        "outputId": "7663831e-d243-441c-b109-54bd8332b154"
      },
      "source": [
        "for batch in train_batches:\r\n",
        "    print(batch.premise.shape)\r\n",
        "    print(batch.hypothesis.shape)\r\n",
        "    print(batch.label.shape)\r\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([40, 512])\n",
            "torch.Size([28, 512])\n",
            "torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pEi1OuxXuuC",
        "outputId": "9cdfc738-9d40-4a41-e926-6720b0ac81a1"
      },
      "source": [
        "net = Net(input_size, embedding_size, hidden_size, output_size, pad_idx).to(device)\r\n",
        "net"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embedding): Embedding(23566, 300, padding_idx=1)\n",
              "  (fc_in): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (lstm_layers): LSTM(300, 300, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (fc_layers): ModuleList(\n",
              "    (0): Linear(in_features=1200, out_features=1200, bias=True)\n",
              "    (1): Linear(in_features=1200, out_features=1200, bias=True)\n",
              "    (2): Linear(in_features=1200, out_features=1200, bias=True)\n",
              "  )\n",
              "  (fc_out): Linear(in_features=1200, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5xZzoRdYebf"
      },
      "source": [
        "def count_parameters(net):\r\n",
        "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgDhXCRjYvUW",
        "outputId": "9f0d9a04-020f-4aa2-cbf7-5910d1c812dd"
      },
      "source": [
        "count_parameters(net)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15096903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvzJf6MHYUzk"
      },
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\r\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDjzQ_BsFVuO"
      },
      "source": [
        "def get_accuracy(preds, y):\r\n",
        "    preds = preds.argmax(dim=1, keepdim=True)\r\n",
        "    correct = preds.squeeze(1).eq(y)\r\n",
        "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\r\n",
        "\r\n",
        "    return acc.item()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvh5sWfSFS-7"
      },
      "source": [
        "def loop(net, batches, train):\r\n",
        "    batch_losses = []\r\n",
        "    batch_accs = []\r\n",
        "\r\n",
        "    if train:\r\n",
        "        print(\"Train Loop:\")\r\n",
        "        net.train()\r\n",
        "        for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "            prem = batch.premise.to(device)\r\n",
        "            hypo = batch.hypothesis.to(device)\r\n",
        "            labels = batch.label.to(device)\r\n",
        "\r\n",
        "            preds = net(prem, hypo)\r\n",
        "            loss = loss_fn(preds, labels)\r\n",
        "            acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "            opt.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            opt.step()\r\n",
        "\r\n",
        "            batch_losses.append(loss.item())\r\n",
        "            batch_accs.append(acc)\r\n",
        "\r\n",
        "    else:\r\n",
        "        print(\"Inference Loop:\")\r\n",
        "        net.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "                prem = batch.premise.to(device)\r\n",
        "                hypo = batch.hypothesis.to(device)\r\n",
        "                labels = batch.label.to(device)\r\n",
        "\r\n",
        "                preds = net(prem, hypo)\r\n",
        "                loss = loss_fn(preds, labels)\r\n",
        "                acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "                batch_losses.append(loss.item())\r\n",
        "                batch_accs.append(acc) \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"\")\r\n",
        "    \r\n",
        "    return sum(batch_losses) / len(batch_losses), sum(batch_accs) / len(batch_accs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fPCpopJ2iOW"
      },
      "source": [
        "def predict(net, p, h):\r\n",
        "    net.eval()\r\n",
        "    premise = [t.lower() for t in TEXT.tokenize(p)]\r\n",
        "    hypothesis = [t.lower() for t in TEXT.tokenize(h)]\r\n",
        "\r\n",
        "    premise = [TEXT.vocab.stoi[t] for t in premise]\r\n",
        "    hypothesis = [TEXT.vocab.stoi[t] for t in hypothesis]\r\n",
        "\r\n",
        "    premise = torch.LongTensor(premise).unsqueeze(1).to(device)\r\n",
        "    hypothesis = torch.LongTensor(hypothesis).unsqueeze(1).to(device)\r\n",
        "    \r\n",
        "    preds = net(premise, hypothesis)\r\n",
        "    preds = preds.argmax(dim=1)\r\n",
        "    \r\n",
        "    print(LABEL.vocab.itos[preds.item()])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIND6JYy5C8H"
      },
      "source": [
        "premise = \"the dog is eating food\"\r\n",
        "hypothesis = \"the dog is playing in the park\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyG5t60WCEfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61767ba-e63f-412e-d01b-ab7b8b947082"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    train_loss, train_acc = loop(net, train_batches, True)\r\n",
        "    val_loss, val_acc = loop(net, test_batches, False)\r\n",
        "    \r\n",
        "    print(f\"epoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")\r\n",
        "    predict(net, premise, hypothesis)\r\n",
        "    print(\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.76it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 26.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.36it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 0 | train_loss: 0.7901 | train_acc: 0.6468 | val_loss: 0.6792 | val_acc: 0.7123\n",
            "contradiction\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:07<00:00,  5.71it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 26.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.66it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 1 | train_loss: 0.6519 | train_acc: 0.7275 | val_loss: 0.6125 | val_acc: 0.7464\n",
            "contradiction\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.76it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 26.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.62it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 2 | train_loss: 0.5889 | train_acc: 0.7592 | val_loss: 0.5915 | val_acc: 0.7510\n",
            "contradiction\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.76it/s]\n",
            " 10%|█         | 2/20 [00:00<00:00, 19.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.71it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 3 | train_loss: 0.5425 | train_acc: 0.7816 | val_loss: 0.5687 | val_acc: 0.7689\n",
            "contradiction\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.74it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 26.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.53it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 4 | train_loss: 0.5133 | train_acc: 0.7955 | val_loss: 0.5587 | val_acc: 0.7739\n",
            "neutral\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:08<00:00,  5.70it/s]\n",
            " 10%|█         | 2/20 [00:00<00:00, 19.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.24it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 5 | train_loss: 0.4705 | train_acc: 0.8144 | val_loss: 0.5529 | val_acc: 0.7768\n",
            "neutral\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.74it/s]\n",
            " 10%|█         | 2/20 [00:00<00:00, 19.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.59it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 6 | train_loss: 0.4392 | train_acc: 0.8275 | val_loss: 0.5613 | val_acc: 0.7811\n",
            "neutral\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:06<00:00,  5.74it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 27.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 35.11it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 7 | train_loss: 0.4099 | train_acc: 0.8408 | val_loss: 0.5826 | val_acc: 0.7750\n",
            "neutral\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:07<00:00,  5.74it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 27.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.62it/s]\n",
            "  0%|          | 0/1073 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 8 | train_loss: 0.3812 | train_acc: 0.8524 | val_loss: 0.6299 | val_acc: 0.7760\n",
            "contradiction\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1073/1073 [03:08<00:00,  5.70it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 26.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 34.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 9 | train_loss: 0.3538 | train_acc: 0.8638 | val_loss: 0.6193 | val_acc: 0.7779\n",
            "neutral\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfhESqydYUwN"
      },
      "source": [
        "def save_checkpoint(net, opt, filename):\r\n",
        "    check_point = {\"net_dict\": net.state_dict(), \"opt_dict\": opt.state_dict()}\r\n",
        "    torch.save(check_point, filename)\r\n",
        "    print(\"Checkpoint Saved!\")\r\n",
        "\r\n",
        "def load_checkpoint(net, opt, filename):\r\n",
        "    check_point = torch.load(filename)\r\n",
        "    net.load_state_dict(check_point[\"net_dict\"])\r\n",
        "    opt.load_state_dict(check_point[\"opt_dict\"])\r\n",
        "    losses = check_point[\"losses\"]\r\n",
        "    print(\"Checkpoint Loaded!\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJJwYa4Xuqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb21585-0662-4795-cc6e-3537ea0a510e"
      },
      "source": [
        "save_checkpoint(net, opt, \"checkpoint.pth.tar\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u7selzCMDVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e66a141-8372-4743-ad1b-e10868ab6968"
      },
      "source": [
        "premise = 'a man sitting on a green bench.'\r\n",
        "hypothesis = 'a woman sitting on a green bench.'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "contradiction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSCJnQKkpg7Y",
        "outputId": "a21162a7-f4f8-4cb1-ab12-d2f00d5ed5df"
      },
      "source": [
        "premise = 'a man sitting on a green bench.'\r\n",
        "hypothesis = 'a man sitting on a blue bench.'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "contradiction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYyI5MZLpg45",
        "outputId": "294b4d73-3bdb-49af-8828-2747a40508dd"
      },
      "source": [
        "premise = 'a dog has finished eating'\r\n",
        "hypothesis = 'a dog is waiting for her next meal'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UNbm3Hspokp",
        "outputId": "318426cf-fc68-448a-da6c-1b6aadb96dc9"
      },
      "source": [
        "premise = 'a horse is running.'\r\n",
        "hypothesis = 'a horse is training for a race'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xWK55JFqnZf",
        "outputId": "783b1db0-1701-4dcb-d642-4cc3275015ea"
      },
      "source": [
        "premise = 'a girl is driving the car'\r\n",
        "hypothesis = 'a girl is drving to her home in the car'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw9CycZbqxtu",
        "outputId": "349b0d61-dc1c-45ec-b7d2-c5365cfdf07d"
      },
      "source": [
        "premise = 'a lady sits on a bench that is aganist a shopping mall'\r\n",
        "hypothesis = 'a person sits on a bench'\r\n",
        "\r\n",
        "predict(net, premise, hypothesis)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entailment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-7DgfHrGYO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGuUiAmLKUZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}